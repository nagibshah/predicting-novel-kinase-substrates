---
title: "Group16_Project2"
group: 16
member: Nagib Shah / Ling Qi / Xinan Ma / Young Choi
author: "Ling Qi"
date: "19 September 2017"
output: html_document
---

# install packages 
```{r, echo=FALSE, warning=FALSE}

install.packages("tibble") # this is for RSSL
install.packages("RSSL")
install.packages("upclass")
install.packages("mclust")
install.packages("caret")
install.packages("lme4")
install.packages("randomForest")
install.packages("RecordLinkage")
install.packages("knitr")
install.packages("XLConnect")
install.packages("class")
install.packages("purrr")
install.packages("mlbench")
install.packages("adabag")
install.packages("kknn")
install.packages("fastAdaboost")
install.packages("gbm")
install.packages("lattice")
install.packages("ggplot2")
install.packages("Rcpp")
install.packages("caret")
install.packages("ddalpha")
install.packages("tidyr")
install.packages("pROC")
## try http:// if https:// URLs are not supported
source("https://bioconductor.org/biocLite.R")
biocLite("Biostrings")

#install if necessary
source("http://bioconductor.org/biocLite.R")
biocLite("seqLogo")

```

# set up your root working directory
```{r, warning=FALSE}
require(knitr)
opts_knit$set(root.dir = "C:/Users/Ling/Documents/My Study/STAT5003/Project2/Final project/Datasets")

```

# call libraries 
```{r, warning=FALSE, echo=FALSE}
library(mclust)
library(upclass)
library(RSSL)
library(e1071)
library(caret)
library(randomForest)
library(plyr)
library(dplyr)
library(class)
library(e1071)
library(gbm)
library(ggplot2)
library(scales)
library(lubridate)
library(stringr)
library(rpart)
library(data.table)
library(tidyr)
library(mlbench)
library(kknn)
library(fastAdaboost)
library(gbm)
library(Biostrings)
library(lattice)
library(ggplot2)

```

# Read data
```{r}
#setwd("C:/Users/Ling/Documents/My Study/STAT5003/Project2/Final project")
# load full data set
dt.Insulin <- read.delim("datasets/InsulinPhospho.txt")
#dim(dt.Insulin)

# load partially labeled data set
dt.Akt <- read.delim("datasets/Akt_substrates.txt", header = F)
dt.mTOR <- read.delim("datasets/mTOR_substrates.txt", header = F)   
#dim(dt.Akt)
#dim(dt.mTOR)

# map labled to the full data set 
dt.Insulin$Kinases[dt.Insulin$Identifier %in% dt.Akt$V1] <- "Akt"
dt.Insulin$Kinases[dt.Insulin$Identifier %in% dt.mTOR$V1] <- "mTOR"
unique(dt.Insulin$Kinases)
# generate a subset of the labelled data 
dt.labeled <- dt.Insulin[which(dt.Insulin$Kinases == 'Akt' | dt.Insulin$Kinases == 'mTOR'), ]

```

# summarize data 
```{r}

head(dt.Insulin)
head(dt.labeled)

# remove the identifier column since it is just a phosphorilation site  
dt.labeled$Identifier <- NULL
dt.labeled$Kinases <- as.factor(dt.labeled$Kinases) # only two classes so set as a factor
dt.labeled$Kinases <- as.numeric(dt.labeled$Kinases) # only two classes so set as a factor
dt.labeled$Seq.Window <- as.character(dt.labeled$Seq.Window) # convert from factor to character
head(dt.labeled)
str(dt.labeled)

```

# Analysize data 
# Attempt to do a pairwise plot of the features to understand if the labelled data is separable
```{r}

#install.packages("lattice")
#install.packages("ggplot2")

filteredFeatures <- c("Avg.Fold","AUC","Ins.1","Ins.2","LY","MK","Kinases")
temporalFeatures <- c("X15s","X30s","X1m","X2m","X5m","X10m","X20m","X60m","Kinases")

# try plotting the temporal data 
pairs(Kinases~., dt.labeled[,temporalFeatures], col=dt.labeled[,temporalFeatures]$Kinases)

# try plotting the other features 
# pair-wise scatterplots colored by class
pairs(Kinases~., dt.labeled[,filteredFeatures], col=dt.labeled[,filteredFeatures]$Kinases)

### appears to indicate that the labeled data can be separated. Thinking SVM should work.

```

# seq.window pattern transformation

```{r, warning=FALSE, echo=FALSE}

dt.labeled.mTOR <-  dt.Insulin[which(dt.Insulin$Kinases == 'mTOR'), ]
dt.labeled.Akt <- dt.Insulin[which(dt.Insulin$Kinases == 'Akt'), ]
dt.Insulin$Seq.Window <- as.character(dt.Insulin$Seq.Window)

# 7th Position is the phospho site
# total of 13 amino acids in the sequence window
phosphoSites.Akt.allSequences <- substr(dt.labeled.Akt$Seq.Window, 1,13)
phosphoSites.mTOR.allSequences <- substr(dt.labeled.mTOR$Seq.Window, 1,13)

# akt sequences
aktSequences <-  t(data.frame(strsplit(phosphoSites.Akt.allSequences, "")))
colnames(aktSequences) <- paste("", 1:13, sep = "")

# mtor sequences
mTORSequences <-  t(data.frame(strsplit(phosphoSites.mTOR.allSequences, "")))
colnames(mTORSequences) <- paste("", 1:13, sep = "")

# generate the consensus Matrix 

aktSequences.pfm <- consensusMatrix(phosphoSites.Akt.allSequences) #, as.prob = T)
colnames(aktSequences.pfm) <- colnames(aktSequences)

mTORSequences.pfm <- consensusMatrix(phosphoSites.mTOR.allSequences) # , as.prob = T) #as.prob = TRUE
colnames(mTORSequences.pfm) <- colnames(mTORSequences)

```

## visualise the patterns 

```{r, warning=FALSE}

# visualise the patterns
library(RColorBrewer)

par(mfrow=c(1, 1), mar=c(3, 3, 3, 3) + 0.1)
barplot(aktSequences.pfm, col=brewer.pal(nrow(aktSequences.pfm), "Paired"),
            legend.text = rownames(aktSequences.pfm),
            args.legend=list(x=ncol(aktSequences.pfm) + 5,y=max(colSums(aktSequences.pfm))+4,bty = "n"),
            main="Akt Sequence Window patterns")

par(mfrow=c(1, 1), mar=c(3, 3, 3, 3) + 0.1)
barplot(mTORSequences.pfm, col=brewer.pal(nrow(mTORSequences.pfm), "Paired"),
            legend.text = rownames(mTORSequences.pfm),
            args.legend=list(x=ncol(mTORSequences.pfm)+5,y=max(colSums(mTORSequences.pfm))+4,bty = "n"),
            main="mTOR Sequence Window patterns")

```

## pattern match score 

```{r}

# Pattern match score
# * Basic Formula  
#   + With the probabbility matrix (PSSM) it is possible to calculate a total score for a specific sequence
#   + The higher the score is, the higher is the probability that the sequence contains the searched motif.
#   + Convert the sequence window in the unlabelled dataset to a sum based on the Position-specific Scoring Matrix (PSSM)

library(seqLogo)

aktSequences.pfm <- consensusMatrix(phosphoSites.Akt.allSequences, as.prob = T)
colnames(aktSequences.pfm) <- colnames(aktSequences)

mTORSequences.pfm <- consensusMatrix(phosphoSites.mTOR.allSequences, as.prob = T) 
colnames(mTORSequences.pfm) <- colnames(mTORSequences)

# motif calculations function 
getMatchScore <- function(seq, PSSM) {
  x <- strsplit(x=seq,split='')
  #x
  #initialise vector to keep scores
  seq_score <- vector()
  #get the corresponding values from the PSSM
  for (i in 1:nchar(seq)){
    if (x[[1]][i] != "_") {
      seq_score[i] <- PSSM[x[[1]][i],i]
    }
    else seq_score[i] = 0.00
  }
  #seq_score
  sum(seq_score)
   
  #max score
  #sum(apply(mm,2,max))
  
}

getPercentageMatch <- function (score, max) {
  # normalise score to 0-1
  score / max
}

dt.Insulin$AktMotif <- as.numeric(lapply(dt.Insulin$Seq.Window, getMatchScore, PSSM=aktSequences.pfm))
dt.Insulin$mTORMotif <- as.numeric(lapply(dt.Insulin$Seq.Window, getMatchScore, PSSM=mTORSequences.pfm))

maxMotifAkt <- max(dt.Insulin$AktMotif)
minMotifAkt <- min(dt.Insulin$AktMotif)
maxMotifmTOR <- max(dt.Insulin$mTORMotif)
minMotifmTOR <- min(dt.Insulin$mTORMotif)

# normalised score
dt.Insulin$aktMotifMatch <- as.numeric(lapply(dt.Insulin$AktMotif, getPercentageMatch, max=maxMotifAkt))
dt.Insulin$mTORMotifMatch <- as.numeric(lapply(dt.Insulin$mTORMotif, getPercentageMatch, max=maxMotifmTOR))


```

# summary of the new features motif

```{r}
#View(dt.unlabeled)
head(dt.Insulin)
unique(dt.Insulin$Kinases)

max(dt.Insulin$AktMotif)
min(dt.Insulin$AktMotif)

max(dt.Insulin$mTORMotif)
min(dt.Insulin$mTORMotif)

dt.labeled.mTOR <-  dt.Insulin[which(dt.Insulin$Kinases == 'mTOR'), ]
dt.labeled.Akt <- dt.Insulin[which(dt.Insulin$Kinases == 'Akt'), ]
```

# feature extraction 

```{r, warning=FALSE}
# this part reference PengYi's code ....
str(dt.Insulin)
dt.Insulin.feat <- dt.Insulin[, c("Identifier", "X15s", "X30s", "X1m", "X2m", "X5m", "X10m", "X20m", "X60m")]
dt.Insulin.feat$X0s <- 0 
head(dt.Insulin.feat)

#### secondary feature 1
# magnitude calculation (mathematical mean)
average.score <- rowSums(dt.Insulin.feat[, 2:9]) / ncol(dt.Insulin.feat[, 2:9])
names(average.score) <- rownames(dt.Insulin.feat)
head(average.score)

#### secondary feature 2
# temporal profile fitting to check if the profile follows are good trend
fitting.score <- c()
for (i in 1:nrow(dt.Insulin)) {
   y <- as.numeric(dt.Insulin[i, 2:10]);
   x <- 2:10
   x2 = x^2
   lmfit <- lm(formula = y ~ x + x2 - 1)
   f.stat <- summary(lmfit)$fstatistic
   fitting.score <- c(fitting.score, f.stat[1])
}
fitted.score <- log2(fitting.score)
names(fitted.score) <- rownames(dt.Insulin.feat)

# combine extracted secondary features with primary features
dt.Insulin.feat <- cbind(fitted.score, dt.Insulin.feat) # removed avg score since same as avg fold
head(dt.Insulin.feat)

dt.Insulin <- merge(dt.Insulin, dt.Insulin.feat, by=c("Identifier", "X15s", "X30s", "X1m", "X2m", "X5m", "X10m", "X20m", "X60m"))
dt.Insulin$X0s <- NULL
head(dt.Insulin)

# average fold and average score are the same. already provided

```

# model analysis and select the best fit model

## setup 

```{r}

# total 16 features approx
predictorsAkt <- c("X15s", "X30s", "X1m", "X2m", "X5m", "X10m", "X20m", "X60m", "Avg.Fold", "AUC", "Ins.1", "LY", "Ins.2", "MK", "fitted.score","aktMotifMatch","Kinases")

predictorsmTOR <- c("X15s", "X30s", "X1m", "X2m", "X5m", "X10m", "X20m", "X60m", "Avg.Fold", "AUC", "Ins.1", "LY", "Ins.2", "MK", "fitted.score","mTORMotifMatch","Kinases")

dt.labeled.mTOR <-  dt.Insulin[which(dt.Insulin$Kinases == 'mTOR'), ]
dt.labeled.Akt <- dt.Insulin[which(dt.Insulin$Kinases == 'Akt'), ]
dt.unlabelled <- dt.Insulin[which(is.na(dt.Insulin$Kinases)), ]

dt.feature.selection.akt <- dt.labeled.Akt[,predictorsAkt]
dt.feature.selection.akt$Kinases <- 1
dt.feature.selection.mTOR <- dt.labeled.mTOR[,predictorsmTOR]
dt.feature.selection.mTOR$Kinases <- 1

dim(dt.feature.selection.akt)
dim(dt.feature.selection.mTOR)

# pick 22 random for akt negatives
set.seed(55)
aktNeg <- sample(x=1:nrow(dt.unlabelled), size=nrow(dt.feature.selection.akt))
temp <- dt.unlabelled[aktNeg, predictorsAkt]
temp$Kinases <- -1
dt.feature.selection.akt <- rbind(dt.feature.selection.akt, temp)
temp <- NULL

# pick 26 random mtor negatives
set.seed(65)
mtorNeg <- sample(x=1:nrow(dt.unlabelled), size=nrow(dt.feature.selection.mTOR))
temp <- dt.unlabelled[mtorNeg, predictorsmTOR]
temp$Kinases <- -1
dt.feature.selection.mTOR <- rbind(dt.feature.selection.mTOR, temp)
temp <- NULL

# final sets for feature selection exercise
dt.feature.selection.akt$Kinases <- as.factor(dt.feature.selection.akt$Kinases)
dt.feature.selection.mTOR$Kinases <- as.factor(dt.feature.selection.mTOR$Kinases)
colnames(dt.feature.selection.akt)[17] <- "Class"
colnames(dt.feature.selection.mTOR)[17] <- "Class"

dim(dt.feature.selection.akt)
dim(dt.feature.selection.mTOR)

# helpers 

sampleData <- function (positives, featureSpace) {
      colnames(positives)[17] <- "Kinases" # change col name 
      featureSpace <- colnames(positives)
      #set.seed(33)
      randomsamples <- sample(nrow(dt.unlabelled), size=nrow(positives), replace = FALSE)
      #print(randomsamples)
      #print(randomsamples)
      negatives <- dt.unlabelled[randomsamples, featureSpace]
      negatives$Kinases <- -1
      # make a balanced set
      balanced <- rbind(positives, negatives)
      colnames(balanced)[17] <- "Class" # change col name
      return(balanced)
}

AnalyseModels <- function (method, data) {
  # prepare training scheme utilising LOOCV
  control <- trainControl(method="repeatedcv", number=10, repeats=3)
  controlLOOCV <- trainControl(method="LOOCV")
  
  model <- NULL
  
  #set.seed(5)
  switch(method, 
  kknn={
    model <- train(Class~., data=data, method=method, trControl=controlLOOCV)
  },
  svmRadial={
    tuneGrid <- expand.grid(sigma=seq(0.1,1,0.1),C=seq(0.1,5,0.5))
    model <- train(Class~., data=data, method=method, trControl=controlLOOCV,tuneGrid=tuneGrid)
  },
  svmLinear={
    tuneGrid <- expand.grid(C=seq(0.1,5,0.5))
    model <- train(Class~., data=data, method=method, trControl=controlLOOCV, tuneGrid=tuneGrid)
  },
  svmPoly={
    tuneGrid <- expand.grid(degree=(1:5),scale=seq(0.1,1,0.1),C=seq(0.1,5,0.5))
    model <- train(Class~., data=data, method=method, trControl=controlLOOCV, tuneGrid=tuneGrid)
  },
  {
    model <- train(Class~., data=data, method=method, trControl=controlLOOCV)
  }
  )
  #model <- train(Class~., data=data, method=method, trControl=controlLOOCV)
  print(model$bestTune)
  # resample data for testing and keep the same positives
  train <- sampleData(positives=data[which(data$Class == 1),])
  
  # predict on training set 
  pred <- predict(model$finalModel, train[,-17])
  if (method=="lda") {
    rocModel <- roc(train[, 17], as.numeric(pred$class))  
  }
  else {
    rocModel <- roc(train[, 17], as.numeric(pred))  
  }
  
  return(rocModel)
}

```

## run through some models to pick best one for AKT

```{r, warning=FALSE}

library(pROC)

#model <- train(Class~., data=dt.feature.selection.akt, method="svmRadial", trControl=controlLOOCV)

# knn model 
rocKnn <- AnalyseModels("kknn",dt.feature.selection.akt)
rocSvmR <- AnalyseModels("svmRadial",dt.feature.selection.akt)
rocSvmL <- AnalyseModels("svmLinear",dt.feature.selection.akt)
rocSvmP <- AnalyseModels("svmPoly",dt.feature.selection.akt)
rocLda <- AnalyseModels("lda",dt.feature.selection.akt)
#modelGbm <- AnalyseModels("gbm",dt.feature.selection.akt)


plot(rocKnn, legacy.axes = TRUE, col="red", lty=3, main="Akt model performances")
lines(rocSvmR, col="blue", lty=2)
lines(rocSvmL, col="green3", lty=1)
lines(rocSvmP, col="orange", lty=2)
lines(rocLda, col="purple", lty=3)

legend("bottomright", inset = .05, legend=c("KNN", "SVM Radial", "SVM Linear", "SVM Poly", "LDA"), col = c("red", "blue", "green3", "orange","purple"), lty=c(3, 2, 1, 2, 3))

```

## run through some models to pick best one for mTOR 

```{r, warning=FALSE}

# knn model 
rocKnn <- AnalyseModels("kknn",dt.feature.selection.mTOR)
rocSvmR <- AnalyseModels("svmRadial",dt.feature.selection.mTOR)
rocSvmL <- AnalyseModels("svmLinear",dt.feature.selection.mTOR)
rocSvmP <- AnalyseModels("svmPoly",dt.feature.selection.mTOR)
rocLda <- AnalyseModels("lda",dt.feature.selection.mTOR)
#modelGbm <- AnalyseModels("gbm",dt.feature.selection.akt)


plot(rocKnn, legacy.axes = TRUE, col="red", lty=3, main="mTOR model performances")
lines(rocSvmR, col="blue", lty=2)
lines(rocSvmL, col="green3", lty=1)
lines(rocSvmP, col="orange", lty=2)
lines(rocLda, col="purple", lty=3)

legend("bottomright", inset = .05, legend=c("KNN", "SVM Radial", "SVM Linear", "SVM Poly", "LDA"), col = c("red", "blue", "green3", "orange","purple"), lty=c(3, 2, 1, 2, 3))

```

# feature selection 
## setup
```{r, warning=FALSE}

library(mlbench)
library(caret)

# total 16 features approx
predictorsAkt <- c("X15s", "X30s", "X1m", "X2m", "X5m", "X10m", "X20m", "X60m", "Avg.Fold", "AUC", "Ins.1", "LY", "Ins.2", "MK", "fitted.score","aktMotifMatch","Kinases")

predictorsmTOR <- c("X15s", "X30s", "X1m", "X2m", "X5m", "X10m", "X20m", "X60m", "Avg.Fold", "AUC", "Ins.1", "LY", "Ins.2", "MK", "fitted.score","mTORMotifMatch","Kinases")

dt.labeled.mTOR <-  dt.Insulin[which(dt.Insulin$Kinases == 'mTOR'), ]
dt.labeled.Akt <- dt.Insulin[which(dt.Insulin$Kinases == 'Akt'), ]
dt.unlabelled <- dt.Insulin[which(is.na(dt.Insulin$Kinases)), ]

dt.feature.selection.akt <- dt.labeled.Akt[,predictorsAkt]
dt.feature.selection.akt$Kinases <- 1
dt.feature.selection.mTOR <- dt.labeled.mTOR[,predictorsmTOR]
dt.feature.selection.mTOR$Kinases <- 1

dim(dt.feature.selection.akt)
dim(dt.feature.selection.mTOR)

# pick 22 random for akt negatives
aktNeg <- sample(x=1:nrow(dt.unlabelled), size=nrow(dt.feature.selection.akt))
temp <- dt.unlabelled[aktNeg, predictorsAkt]
temp$Kinases <- -1
dt.feature.selection.akt <- rbind(dt.feature.selection.akt, temp)
temp <- NULL

# pick 26 random mtor negatives
mtorNeg <- sample(x=1:nrow(dt.unlabelled), size=nrow(dt.feature.selection.mTOR))
temp <- dt.unlabelled[mtorNeg, predictorsmTOR]
temp$Kinases <- -1
dt.feature.selection.mTOR <- rbind(dt.feature.selection.mTOR, temp)
temp <- NULL

# final sets for feature selection exercise
dim(dt.feature.selection.akt)
dim(dt.feature.selection.mTOR)
```
## helpers  
```{r}

tstatSort <- function (train) {
  train.byClass <- split(train[,-17], train$Kinases)

  # perform a t-test
  feature.pvalues <- c()
  for(i in 1:(ncol(train)-1)) {
    feature.pvalues <- c(feature.pvalues, t.test(train.byClass[[1]][,i], train.byClass[[2]][,i])$p.value)
  }
  names(feature.pvalues) <- colnames(train[,-17])
  
  # filter the top most discriminative feature based on p-values
  filtered.features <- names(sort(feature.pvalues)) #[1:10])
  filtered.features
}

selectFeature <- function(train, cls.train, features) {
  ## identify a feature to be selected
  current.best.accuracy <- -Inf
  selected.i <- NULL
  for(i in 1:ncol(train)) {
    current.f <- colnames(train)[i]
    #print(paste("Iteration:", i))
    #print(paste("Current col:", current.f))
    if(!current.f %in% features) {
      # carry out a LOOCV
      set.seed(99)
      fold <- createFolds(cls.train, k=nrow(train))
      
      test.accuracies <- c()
      
      for(i in 1:length(fold)) {
        truth <- cls.train[fold[[i]]]
        trainingData <- train[-fold[[i]], c(features, current.f)]
        testingData <- train[fold[[i]],c(features, current.f)]
        #print(truth)
        svm.model <- svm(x=trainingData, y=cls.train[-fold[[i]]], kernel="polynomial", type="C-classification")
        pred <- predict(svm.model, testingData)
        #print(pred)
        accuracy <- sum(pred == truth) / length(truth)
        test.accuracies <- c(test.accuracies, accuracy)
      }
      
      # take the avg test accuracy as benchmark 
      test.acc <- mean(test.accuracies)
      
      if(test.acc > current.best.accuracy) {
        #print("next best found")
        #print(test.acc)
        #print(current.best.accuracy)
        current.best.accuracy <- test.acc
        selected.i <- current.f #colnames(train)[i]
      }
    }
  }
  
  return(selected.i)
}

backwardStepwise <- function(train, cls.train, sortedFeatures) {

  test.acc <- c() 
  
  # carry out a LOOCV
  set.seed(99)
  fold <- createFolds(cls.train, k=nrow(train))
  
  # remove the least useful predictor one at a time
  for (i in length(sortedFeatures):1) {
	  current.f <- colnames(train)[i]
	  features <- sortedFeatures[1:i]
	  #print(features)
	  
    test.accuracies <- c()
	  
	  for(i in 1:length(fold)) {
        truth <- cls.train[fold[[i]]]
        trainingData <- train[-fold[[i]], features]
        testingData <- train[fold[[i]],features]
        #print(truth)
        svm.model <- svm(x=trainingData, y=cls.train[-fold[[i]]], kernel="polynomial", type="C-classification")
        pred <- predict(svm.model, testingData)
        #print(pred)
        accuracy <- sum(pred == truth) / length(truth)
        test.accuracies <- c(test.accuracies, accuracy)
	  }
	  
	  # take the avg test accuracy as benchmark 
    test.acc <- c(test.acc, mean(test.accuracies))
	  
  }
  
  return(test.acc)
}

# run the random sampling XX times to see if the result is different
randomAccuracies <- function(positives, featureSpace, sortedFeatures, iterations) {
  accuracies.all <- data.frame()
  #names(accuracies.all) <- seq(length(sortedFeatures), 1)
  for (i in 1:iterations) {
    # pick 22 random for negatives
    set.seed(i)
    randomsamples <- sample(nrow(dt.unlabelled), size=nrow(positives), replace = FALSE)
    #print(randomsamples)
    negatives <- dt.unlabelled[randomsamples, featureSpace]
    negatives$Kinases <- -1
    # make a balanced set
    balanced <- rbind(positives, negatives)
    # run the wrapper selection process
    accuracies <- backwardStepwise(train = balanced[,-17],
                                        cls.train = balanced[,17],
                                        sortedFeatures = sortedFeatures)
    #accuracies <- data.frame(accuracies)
    #names(accuracies) <- seq(length(sortedFeatures), 1)
    accuracies.all <- rbind(accuracies.all, accuracies)
  }
  names(accuracies.all) <- seq(length(sortedFeatures), 1)
  return(accuracies.all)
}


```

## run the wrapper feature selection (SVM)

```{r}

# carry out t-test to sort features
featuresAkt <- tstatSort(dt.feature.selection.akt)
# sorted features 
featuresAkt
# best feature as per t-test
featuresAkt[1]

# carry out t-test to sort features
featuresmTOR <- tstatSort(dt.feature.selection.mTOR)
# sorted features 
featuresmTOR
# best feature as per t-test
featuresmTOR[1]

```
## forward stepwise 
### akt 
```{r}

forwardFeatures <- c(featuresAkt[1])
# select the 2 to x best features using knn as a wrapper classifier
for (j in 2:ncol(dt.feature.selection.akt)) { # ncol(dt.feature.selection.akt)
  selected.i <- selectFeature(train = dt.feature.selection.akt[,-17],
                              cls.train = dt.feature.selection.akt[,17],
                              features = forwardFeatures)
  print(selected.i)

  # add the best feature from current run
  forwardFeatures <- c(forwardFeatures, selected.i)
}

```
### mtor 

```{r}

forwardFeatures <- c(featuresmTOR[1])
# select the 2 to x best features using knn as a wrapper classifier
for (j in 2:ncol(dt.feature.selection.mTOR)) { # ncol(dt.feature.selection.akt)
  selected.i <- selectFeature(train = dt.feature.selection.mTOR[,-17],
                              cls.train = dt.feature.selection.mTOR[,17],
                              features = forwardFeatures)
  print(selected.i)

  # add the best feature from current run
  forwardFeatures <- c(forwardFeatures, selected.i)
}

```

## backward stepwise 
### akt feature selection with random sampling 

```{r}

# reset the positives
dt.feature.selection.akt <- dt.labeled.Akt[,predictorsAkt]
dt.feature.selection.akt$Kinases <- 1
dt.feature.selection.mTOR <- dt.labeled.mTOR[,predictorsmTOR]
dt.feature.selection.mTOR$Kinases <- 1

test.accuracies.akt <- randomAccuracies(positives = dt.feature.selection.akt, 
                                        featureSpace = predictorsAkt,
                                        sortedFeatures = featuresAkt,
                                        iterations = 100)

```

### mTOR feature selection with random sampling

```{r}

test.accuracies.mtor <- randomAccuracies(positives = dt.feature.selection.mTOR, 
                                        featureSpace = predictorsmTOR,
                                        sortedFeatures = featuresmTOR,
                                        iterations = 100)
```

## plot the results for backwards selection 

```{r}

# avg the results 
test.accuracies.akt.avg <- colMeans(test.accuracies.akt)
test.accuracies.mtor.avg <- colMeans(test.accuracies.mtor)

```

### akt plots

```{r}

plot(rev(test.accuracies.akt.avg),type="l",ylim=c(0.8, 1), xaxt="n", ylab="Test accuracies", xlab="Number of features sorted",main="Feature selection vs model accuracy akt")
axis(1, at=seq(1, 16, by = 1), las=2)

```

### mtor plots

```{r}

plot(rev(test.accuracies.mtor.avg),type="l",ylim=c(0.5, 1), xaxt="n", ylab="Test accuracies", xlab="Number of features sorted",main="Feature selection vs model accuracy mtor")
axis(1, at=seq(1, 16, by = 1), las=2)

```
## feature selection results 
```{r}

# how to best interpret the results?

# akt features 
print("For Akt - 4 most important features yield the best result before performance flatlines")
featuresAkt[1:4]
# mtor features 
print("For mTOR - 8 most important features yield the best result before performance flatlines")
featuresmTOR[1:8]

```

# Adaptive sampling
```{r}

AdaSampling.func <- function(dt.model.full, dt.labeled) {
  
  dt.model.full %>%
    mutate(Class = -1) %>%
    mutate(Class = replace(Class, Identifier %in% dt.labeled$V1, 1)) -> dt.model.full
  
  for (i in 1:1000) {
    
    
  }
  
}

```


# build SVM model based on labeled positive class and the same size randomly selected non-labeled (assume all negative) data 
```{r, warning=FALSE}

# function to build model 
model.func <- function (dt.model.full, dt.labeled, cost.n, degree.n) {

  #dt.model.full <- dt.Akt.fulmodel
  #dt.labeled <- dt.Akt
  last.col = ncol(dt.model.full)-1
  
  dt.model.full %>%
    mutate(Class = -1) %>%
    mutate(Class = replace(Class, Identifier %in% dt.labeled$V1, 1)) -> dt.model.full
  
  # data frame to store pred result
  dt.result <- dt.model.full[, c("Identifier", "Class")]
  
  for (i in 1:1000) {
    
    dt.nolabel.sample <- dt.model.full[dt.model.full$Class==-1,][sample(nrow(dt.model.full[dt.model.full$Class==-1, ]), nrow(dt.labeled)),]
    
    dt.model <- rbind(dt.model.full[dt.model.full$Class==1,], dt.nolabel.sample)
    
    # build SVM classification model incl probability -- temporarily without seq.window
    #print(head(dt.model[, 2:ncol(dt.model)]))
    fit.model <- svm(Class ~ ., data=dt.model[, 2:ncol(dt.model)], kernel="polynomial", type="C-classification", cost=cost.n, degree=degree.n, decision.values = TRUE, probability=TRUE)
    
    #print(head(dt.model.full[, 2:last.col]))
    pred <- predict(fit.model, dt.model.full[, 2:last.col], decision.values = TRUE, probability = TRUE)
  
    dt.result[, ncol(dt.result) + 1] <- attr(pred, "probabilities")[,1]
    
    # build LDA classification model 
    #fit.model <- lda(Class ~ ., data = dt.model[, 2:ncol(dt.model)], CV = TRUE)
    #pred <- predict(fit.model, dt.model.full[, 2:last.col])$Class
    #dt.result[, ncol(dt.result) + 1] <- pred$posterior
    
    #sapply(dt.model.full[, 2:last.col], class)
    #sapply(dt.model[, 2:ncol(dt.model)], class)
    #View(dt.model.full[, 2:last.col])
    names(dt.result)[ncol(dt.result)] <- paste0("model_", i)
    
  }
    
  dt.final <- data.frame(dt.result[,1:2],pred.Means=rowMeans(dt.result[,3:ncol(dt.result)]))
  names(dt.final)[colnames(dt.final)=="pred.Means"] <- "predictResult"
  
  return(dt.final)
  
}

```

## nagibs code to handle plotting of coefficients 

```{r}

#library(raster)

# function to build model 
letThereBeLight <- function (data,cost.n, degree.n) {

  # prep the full unlabelled set
  featureSpace <- colnames(data)
  unlabelled.all <- dt.unlabelled[,featureSpace]
  # data frame to store pred result
  dt.result <- dt.unlabelled[, c("Identifier","Kinases")]
  colnames(unlabelled.all)[17] <- "Class"
  colnames(dt.result)[2] <- "Class"
  colnames(data)[17] <- "Class"
  
  controlLOOCV <- trainControl(method="LOOCV",savePredictions = 'final',classProbs = T)
  #tuneGrid <- expand.grid(sigma=seq(0.1,1,0.3),C=seq(0.1,5,0.5))
  tuneGrid <- expand.grid(sigma=seq(0.1,1,0.5),C=seq(0.1,2,0.5))
  

  # instantiate the last probability values 
  lastProbabilities <- rep(0, nrow(dt.unlabelled))
  iterationCors <- c()
  
  for (i in 1:100) {
    # build a balanced set of data (randomly sampled from unlabelled set)
    balanced <- sampleData(positives=data[which(data$Class == 1),])
    balanced$Class <- as.character(balanced$Class)
    balanced[which(balanced$Class == "1"),]$Class <- "POSITIVE"
    balanced[which(balanced$Class == "-1"),]$Class <- "NEGATIVE"
    balanced$Class <- as.factor(balanced$Class)
    
    
    last.col = ncol(balanced)
    
    # build SVM classification model incl probability
    #fit.model <- svm(Class ~ ., data=balanced, 
    #                 kernel="polynomial", type="C-classification", 
    #                 cost=cost.n, degree=degree.n, 
    #                 decision.values = TRUE, probability=TRUE)
    
    # train run validation and find the best c value for the dataset in question 
    model <- train(Class~., data=balanced, method="svmRadial", trControl=controlLOOCV,tuneGrid=tuneGrid)
    
    # now predict on the full unlabelled set 
    #pred <- predict(fit.model, unlabelled.all[, -last.col], 
    #                decision.values = TRUE, probability = TRUE)
    pred <- predict(model$finalModel, unlabelled.all[, -last.col],type="prob")
    #return(pred)
    # store the probabilities against the identifiers
    currentProbabilities <- pred[,1] # attr(pred, "probabilities")[,1]
    dt.result[, ncol(dt.result) + 1] <- currentProbabilities
    names(dt.result)[ncol(dt.result)] <- paste0("model_", i)
    
    # calculate the correlations and store 
    currentCor <-  cor(currentProbabilities, lastProbabilities)
    iterationCors <- c(iterationCors, currentCor)  
    lastProbabilities <- currentProbabilities
    
  }
    
  # calculate the mean and store the result
  dt.final <- data.frame(dt.result[,1],pred.Means=rowMeans(dt.result[,3:ncol(dt.result)]))
  names(dt.final)[colnames(dt.final)=="pred.Means"] <- "predictResult"
  plot(iterationCors,type="l",#ylim=c(0, 2),
       ylab="correlation", 
       xlab="Number of iterations",
       main="Optimisation point for random sampling")
  #axis(1, at=seq(1, 100, by = 1), las=2)
  
  return(dt.final)
  
}

```

##  find the negative nancies 

### akt nancies 

```{r}

aktNancies <- letThereBeLight(dt.feature.selection.akt, 1, 1)

```

### mTOR nancies 

```{r}

mTORNancies <- letThereBeLight(dt.feature.selection.mTOR, 1, 1)

```

# prediction output
```{r, warning=FALSE}
library(MASS)
# check data before build model
dim(dt.Insulin)
dim(dt.Akt)
dim(dt.mTOR)
head(dt.Insulin)

# SVM to predict Akt - full model without motif
# extract columns for Akt full model
Akt.final.fullmodel <- model.func(dt.Akt.fulmodel, dt.Akt, 1, 1)
Akt.final.fullmodel[Akt.final.fullmodel$Class==1, ]
Akt.final.fullmodel[Akt.final.fullmodel$Identifier %in% dt.mTOR$V1, ]

# SVM to predict mTOR - full model without motif
dt.mTOR.fulmodel <- dt.Insulin[, c("Identifier", "X15s", "X30s", "X1m", "X2m", "X5m", "X10m", "X20m", "X60m", "Avg.Fold", "AUC", "Ins.1", "LY", "Ins.2", "MK", "mTORMotif", "fitted.score")]
dim(dt.mTOR.fulmodel)
mTOR.final.fullmodel <- model.func(dt.mTOR.fulmodel, dt.mTOR, 1, 1)
mTOR.final.fullmodel[mTOR.final.fullmodel$Class==1, ]
mTOR.final.fullmodel[mTOR.final.fullmodel$Identifier %in% dt.Akt$V1, ]

```


# Validation
```{r}

```

# compares prediction diff
# 1. use bootstraping to calculate confidence interval of average difference 
# 2. generates a plot to show distribution of difference 
```{r}

diff.func <- function (type, dt.original, dt.prediction, title) {

# bootstrap sample statistic (difference in prediction probability)
B=1000  
dt.original.B <- rep(0,B)
dt.prediction.B <- rep(0,B)

for ( i in 1:B ) {
  dt.original.B[i] = mean(sample(dt.original[, grep(type, colnames(dt.original))], size = nrow(dt.original), replace = TRUE), na.rm = TRUE)
  dt.prediction.B[i] = mean(sample(dt.prediction[, grep(type, colnames(dt.prediction))], size = nrow(dt.prediction), replace = TRUE), na.rm = TRUE)
}

b.diff<-(dt.original.B-dt.prediction.B)*100

print(paste("95% Confidence Interval of Average(Bootstrap) difference in ", type, round(quantile(b.diff,0.05),2), round(quantile(b.diff,0.95),2)))

dt.delta <- merge(dt.original[, c(which(colnames(dt.original)=="Identifier"), grep(type, colnames(dt.original)))], dt.prediction[, c(which(colnames(dt.prediction)=="Identifier"), grep(type, colnames(dt.prediction)))], by=("Identifier"))

dt.delta$delta<-(dt.delta[,2]-dt.delta[,3])*100
#dt.delta<-dt.delta[complete.cases(dt.delta$delta),] 

ggplot(dat=dt.delta) + geom_histogram(aes(x=delta),bins=50) +ggtitle(paste0(title, " Distribution of prediction difference 2016 minus 2017"))

}

# load prediction_2016 result
options(java.parameters = "-Xmx4g" )
library(XLConnect)

wb = loadWorkbook("datasets/Prediction_2016.xlsx")
df.Akt = readWorksheet(wb, sheet = "Akt_prediction", header = TRUE)
df.mTOR = readWorksheet(wb, sheet = "mTOR_prediction", header = TRUE)

df.Akt %>%
  mutate(Identifier = paste0(str_trim(str_to_upper(df.Akt$GeneSymbol), side="both"), ";",str_trim(df.Akt$Phosphorylation.site, side="both"), ";" )) %>%
  mutate(Full.model.predict = as.numeric(Full.model.predict))  -> df.Akt
names(df.Akt)[colnames(df.Akt)=="Full.model.predict"] <- "predictResult" 

df.mTOR %>%
  mutate(Identifier = paste0(str_trim(str_to_upper(df.mTOR$GeneSymbol), side="both"), ";",str_trim(df.mTOR$Phosphorylation.site, side="both"), ";" )) %>%
  mutate(Full.model.predict = as.numeric(Full.model.predict))  -> df.mTOR
names(df.mTOR)[colnames(df.mTOR)=="Full.model.predict"] <- "predictResult" 


diff.func ("predictResult", df.Akt, Akt.final.fullmodel, "Akt Full Model - ")
diff.func ("predictResult", df.mTOR, mTOR.final.fullmodel, "mTOR Full Model - ")

```

# Output session information
```{r}
sessionInfo()
```

